---
title: "Générateurs de scénarios économiques"
author: "Mehdi KHAIROUN, William LAURENT, Oskar LAVERNY, Pierre MARJOLLET"
header-includes: 
  - \usepackage[francais]{babel}
output:
  pdf_document: default
  html_document: default

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("fonctions utiles.R")
```

&nbsp;
&nbsp;
&nbsp;

\begin{center}
\includegraphics{logoISFAcourt.png}
\end{center}

&nbsp;
&nbsp;
&nbsp;

\tableofcontents

\newpage

# I. Mise en place du framework

## Sujet et cadre d'étude

Ce projet de groupe est effectué dans le cadre du cours de *Générateurs de scénarios économiques* - **GSE** dispensé à l'ISFA. La trame que nous allons suivre est la suivante :

* Création d'un GSE "mono indice" risque neutre
* Calcul de *Best Estimate* - **BE** *empirique* dans le cadre d'un contrat d'épargne en *Unité de Compte* - **UC**
* Etude de la sensibilité induite par le calibrage du modèle sélectionné

## Nos outils

Pour mener à bien ce projet, nous allons exploiter le langage open-source **R** muni des librairies suivantes :

* **ESG** - librairie co-produite en 2013 par Frédérique PLANCHET, enseignant chercheur de l'ISFA. Elle offre une procédure pour valoriser plusieurs produits d'assurance (type épargne, retraite, ...)
* **RMarkdown** - librairie proposée par les fondateurs de RStudio, dans le but de produire des rendus PDF de code. Elle compile le code R et comprend le language *LaTeX*.
* **magrittr** - librairie incoutournable. Elle propose de performants opérateurs plébiscités par les utilisateurs de R pour gagner en lisibilité de code

# II. Création d'un GSE mono-indice

## Paramètres de la modélisation

Les paramètres que nous avons retenus pour la simulation sont les suivants:

* horizon $T=5$ années 
* valeure initiale de l'action $S(0)=100$
* nombre de scénarios $n=10\,000$


## Courbe de taux zéros coupons

### Réglementation

Sous Solvabilité II, le régulateur publie mensuellement des courbes de taux zéro coupons. Ces courbes servent à estimer la valeur actuelle des engagements de l'assureur en acualisant les flux futurs obtenus à partir de simulations de prix d'actifs dans le monde risque neutre. Le régulateur indique également que la publication de courbes de taux permet d'harmoniser et d'auditer les calculs des provisions.

### Méthodologie

La courbe des taux fournie par l'EIOPA est construite sur la base des taux observés sur le marché, tant que ceux-ci sont liquides, c'est à dire jusqu'à un *Last Liquid point* fixé à 20ans. Au-delà, la courbe est extrapolée via la méthodologie de Smith-wilson, qui nécessite un *Ultimate forward rate* comme paramètre d'entrée, fixé par EIOPA.

### Courbe choisie

Nous avons choisi d'utiliser la courbe fournie par l'EIOPA, sans ajustement de volatilité, sans chocs.

## Choix du modèle

Pour plus de simplicité de mise en oeuvre, nous avons choisi d'utiliser les modèles déjà implémentés dans la librairie ESG. Nous présentons dans cette partie la modélisation retenue ainsi que les paramètres initiaux de nos simulations.

Dans la suite, on retiendra les notations suivantes :

* $P(t,T), \forall t \,|\, 1 \le t \le T$, la valeur du zéro coupon actualisée en t
* $R(t,T) = - \frac{log(P(t,T))}{T-t}$ le taux spot continu en t, d'échéance T
* $f(t,T) = \lim\limits_{S \leftarrow T_+}F(t; T, S) := - \frac{d\,logP(t,T)}{d\,T}$ le taux forward instantanné en t, d'échéance T.
* $(r_t = \lim_{T \leftarrow t_+}f(t,T), t \ge 0)$ le taux court en t.

L'unique input de notre modélisation est la courbe de zéro coupons publiée par le régulateur. L'ensemble des autres paramètres, notamment ceux analysés dans la partie portant sur les calculs de sensibilité, ont été choisis à dire d'expert, ou fixés dans des plages.

### Modèle de taux court

Nous modélisons les taux forward instantanés $f$ par *Heath-Jarrow-Merton - HJM*. On a
$$df(t,T) = \mu(t,T)dt + \sigma(t,T)dW_t$$
Ce modèle HJM nous permettra, une fois $f(t,T)$ calibré, de produire les taux courts $r_t$.

D'après le cours de $mathématiques financières$, un critère d'unicité de la mesure martingale en AOA est de définir le drift comme:
$$\mu(t,T)dt = \sigma(t,T) \int\limits_t^T\sigma(t,s)ds$$
Le drift étant une fonction de la volatilité, cela nous simplifie le modèle.

Enfin, nous définissons la structure de volatilité des taux forward par la caractérisation de la volatilité du modèle de Hull-White dans le framework HJM. On choisit
$$\sigma(t,T):=\sigma e^{-k(t-T)}$$
On prendra $k=2$ et $\sigma=0,1$ par défaut.

Nous avons maintenant des valeurs de taux courts et des structures de volatilité des taux forward. La section suivante détaille la construction d'un modèle d'actifs sur cette base.

### Modélisation des actifs

On modélise les actions par le modèle de Black-Scholes comportant un drift non-constant déduit du modèle HJM présenté précédemment:
$$\frac{dS_t}{S_t} = r_tdt + \sigma_{bs}(\rho dW_t^1 + \sqrt{1-\rho ^2}dW_t^2)$$
Ici $\rho$ est un paramètre des sensibilité de l'actif aux 2 facteurs de risque que sont les 2 mouvements browniens.

Nous avons, par défaut, gardé $\rho = 0.5$, et la volatilité constante $\sigma_{bs} = 0.2$ 

### Test de martingalité et cohérence du marché

Enfin, pour nous assurer de la cohérence de nos modélisations, nous vérifions que les actifs actualisés issus de notre modélisation sous la probabilité risque neutre sont bien des martingales. Pour ça, nous vérifions tout simplement qu'à chaque horizon t fixé, nous avons bien que l'actif actualisé en 0 est égal à sa valeur en 0.

```{r, echo = F}
objScenario <- build_gse(ZC = ZC,base.nScenarios = 10000)
mymtgtest(objScenario
          , main = "Test de martingalité des actifs simulés"
          , xlab = "Horizon"
          , ylab = "Moyenne"
          , sub = "Les valeurs obtenues sont divisées par S(0)"
          )

```
Le test de martingalité est plutôt satisfaisant. Le ratio $\frac{S(t)}{P(0,t)} \frac{1}{S(0)}$ est très proche de $1$.

Pour ce qui est de la cohérence de marché (**market consistency**), nous ne sommes ici pas en mesure de la valdider. En effet, le seul paramètre d'entrée de nos modèles est la courbe de taux de l'EIOPA. Nous n'avons aucune base de comparaison que nous pourrions exploiter ici en guise de référence du marché. Ainsi, pour peu que les fonctions que nous utilisons soient codées correctement, ce qui est a priori le cas, la cohérence de marché est *de facto* vérifiée.

# III. Analyse et application à un contrat d'épargne en UC

## Contrat et résultat fondamental

### Le contrat d'épargne en UC

Lors du cours de *Modèles financiers en assurance* donné par M. PLANCHET, nous avons exprimé la valeur théorique du BE d'un contrat d'épargne en UC. Afin de bien définir le cadre de ce contrat, nous nous proposons d'utiliser les notations suivantes :

* Sous-jacent : $(S(t), t\ge0)$
* Investissement initial $S(0)$
* Durée du contrat $T$
* Rachat en $\tau$ permis n'importe quand de fréquence constante
* Pas de prorogation $(\tau \le T)$ - *A terme, le contrat est rachêté*

On définit $\Lambda \, := \sum\limits_{t=1}^{T}\delta(t)F(t)$, $\Lambda$ la somme des flux futurs actualisés nés des engagements de l'assureur auprès de de ses assurés par

* $\delta(t) \, := e^{-\int\limits_{0}^{t}r_u\,du}$ le *discount factor*, $(r_u, u\ge0)$ le taux court
* $F$ les flux représentant les engagements de l'assureur

### Valeur du BE dans un contrat d'épargne en UC

On calcule le best estimate par $BE = \mathbb{E}^{\mathbb{P}\times\mathbb{Q}}(\Lambda)$ avec

* $\mathbb{P}$ la probabilité historique de l'assureur
* $\mathbb{Q}$ la probabilité risque neutre

En considérant que la notion de rachat regroupe les rachats économiques et les rachats par les héritiers du bénéficiaire, on a $F(t)=S(t) \mathbb{1}_{\tau=t}$. On note que dans le cas général $\mathbb{1}_{\tau=t}$ dépend des probabilités $\mathbb{Q}$ et $\mathbb{P}$. Nous avons

$$BE = \sum\limits_{t=1}^{T}\mathbb{E}^{\mathbb{P}\times\mathbb{Q}}(\delta(t) S(t) \mathbb{1}_{\tau=t})$$

En notant $\mathcal{F}_t$ l'information financière disponible en $t$. On a alors
$$BE = \sum\limits_{t=1}^{T}\mathbb{E}^{\mathbb{Q}}(\delta(t) S(t) \mathbb{E}^{\mathbb{P}}(\mathbb{1}_{\tau=t} | \mathcal{F}_t))$$

En notant $q_t := \mathbb{E}^{\mathbb{P}}(\mathbb{1}_{\tau=t} | \mathcal{F}_t)$ la probabilité de rachat, il vient 
$$BE = \sum\limits_{t=1}^{T}\mathbb{E}^{\mathbb{Q}}(\delta(t) S(t) q_t)$$

Comme les taux de rachat sont constants, le calcul de $q_t$ ne dépend ni de l'information financière, ni de la probabilité historique de l'assureur

$$BE = \sum\limits_{t=1}^{T} q_t\mathbb{E}^{\mathbb{Q}}(\delta(t) S(t))$$

Comme dans le monde risque neutre $(\delta(t)S(t), t \ge 1)$ est une martingale sous $\mathbb{Q}$

$$BE=S(0) \sum\limits_{t=1}^{T} q_t$$

Finalement

$$BE=S(0)$$
**En cours, nous avons également démontré que ce résultat reste vrai si les rachats ne sont pas constants**. Ce résultat fondamental va diriger nos études et nous permettre d'être confortés avec les valeurs estimées du BE empirique par la méthode de  Monte Carlo. **Le point central de cette étude sera alors de vérifier ce résultat, et de confirmer que le BE de ce contrat est bien égal au prix initial du sous-jacent modélisé**.

## Calcul du BE empirique

Définissons le BE empirique pour $n$ simulations :

$$\widehat{BE}_n \, := \frac{1}{n}  \sum\limits_{k=1}^{n} \sum\limits_{t=1}^{T} \delta^{(k)}(t)F^{(k)}(t)$$

* $\delta^{(k)}(t)$ la $k^{ième}$ simulation du facteur d'actualisation en $t$
* $F^{(k)}(t)$ la $k^{ième}$ simulation du flux de l'assureur en $t$

Enfin

$$BE = \lim\limits_{n \rightarrow \infty} \widehat{BE}_n$$

## Résultats et temps de convergence

## Sensibilités

Pour des problèmatiques de temps de calcul, nous n'avons pas calculé la sensibilité elle même, mais nous avons affiché sur des graphiques des simulations de BE pour différentes valeurs de chaque paramètre étudié, ceteris paribus. 

Testons les paramètres du modèle HJM présenté en partie II

```{r graph, echo = F, fig.height= 3}
objScenario <- build_gse(ZC = ZC,
                         base.horizon = 5,
                         base.nScenarios = 10000,
                         rt.vol = .1,
                         rt.k = 3,
                         s.vol = .1,
                         s.k = 3,
                         s.volStock = .2,
                         s.stock0 = 100,
                         s.rho=.5)

################################################################ GRAPHIQUES DE SENSIBILITE ####
par(cex.main=0.8,cex.axis=0.8,cex.lab=0.8,oma=c(0,0,0,0),mfrow = c(1,2))
# BE(ZC=ZC,
#    base.horizon = seq(5,30,by=1)) %>% 
#    {plot(.$base.horizon,
#          .$BE,
#          main="BE en fonction de l'horizon du contrat"
#    )
#      abline(h=1)}
BE(ZC=ZC,
   rt.vol = seq(0,1,length.out=100)) %>% 
   {plot(.$rt.vol,
         .$BE,
         main="BE en fonction de la volatilité\n du taux court",
         xlab = "volatilité",
         ylab = "BE"
   )
     abline(h=1)}
BE(ZC=ZC,
   rt.k = seq(1,3,length.out=50)) %>% 
   {plot(.$rt.k,
         .$BE,
         main="BE en fonction du k\n du taux court",
         xlab = "k",
         ylab = "BE"
   )
     abline(h=1)}

```

Pour ce qui est du modèle de taux forward HJM, on observe que modifier les deux paramètres qui le composent ne change pas les résultats significativement, la volatilité des BE simulés semble rester constante, ce qui indique une vitesse de convergence constante.

Passons au modèle action 

```{r sensi_2, echo = FALSE, fig.height= 3}
par(cex.main=0.8,cex.axis=0.8,cex.lab=0.8,oma=c(0,0,0,0),mfrow = c(1,2))
BE(ZC=ZC,
   s.vol = seq(0,1,length.out=100)) %>% 
   {plot(.$s.vol,
         .$BE,
         main="BE en fonction de la volatilité\n du taux court de l'action",
         xlab = "Taux court",
         ylab = "BE"
   )
     abline(h=1)}
BE(ZC=ZC,
   s.k = seq(1,3,length.out=50)) %>% 
   {plot(.$s.k,
         .$BE,
         main="BE en fonction du k\n du taux court de l'action",
         xlab = "k",
         ylab = "BE"
   )
     abline(h=1)}



```

```{r sensi_2_, echo = FALSE, fig.height= 3}
par(cex.main=0.8,cex.axis=0.8,cex.lab=0.8,oma=c(0,0,0,0),mfrow = c(1,2))
BE(ZC=ZC,
   s.volStock = seq(0,1,length.out=100)) %>% 
   {plot(.$s.volStock,
         .$BE,
         main="BE en fonction de la volatilité\n de l'action",
         xlab = "volatilité",
         ylab = "BE"
   )
     abline(h=1)}

BE(ZC=ZC,
   s.stock0 = seq(10,200,length.out=100)) %>% 
   {plot(.$s.stock0,
         .$BE,
         main="BE en fonction la valeur initiale\n de l'action",
         xlab = "S(0)",
         ylab = "BE"
   )
     abline(h=1)}


```


Ici encore, perturber la volatilité et la valeur initiale du sous-jacent ne change pas la valeur estimée du BE  Toutefois, la variance des BE simulés semble être croissante avec la volatilité de l'action, indiquant ainsi une diminution de la vitesse de convergence. Ce résultat semble bien cohérent avec l'idée que l'augmentation de la volatilité du sous-jacent augmente la volatilité du BE d'un produit qui a cet actif pour support. Pousser le nombre de simulations suffirait à corriger cet effet.

```{r sensi_4, echo = FALSE, fig.height= 3}

par(cex.main=0.8,cex.axis=0.8,cex.lab=0.8,oma=c(0,0,0,0),mfrow = c(1,2))
BE(ZC=ZC,
   s.rho=seq(0,1,length.out=100)) %>% 
   {plot(.$s.rho,
         .$BE,
         main="BE en fonction du rho\n de l'action",
         xlab = "rho",
         ylab = "BE"
   )
     abline(h=1)}



```

```{r sensi_5, echo = FALSE, fig.height= 3}

par(cex.main=0.8,cex.axis=0.8,cex.lab=0.8,oma=c(0,0,0,0),mfrow = c(1,2))

BE(ZC=ZC,
   txConjoncturel=seq(0,1,length.out=100)) %>% 
   {plot(.$txConjoncturel,
         .$BE,
         main="BE en fonction du taux de rachat\n conjoncturel",
         xlab = "Taux de rachat",
         ylab = "BE"
   )
     abline(h=1)}

BE(ZC=ZC,
   txStructurel=seq(0,1,length.out=100)) %>% 
   {plot(.$txStructurel,
         .$BE,
         main="BE en fonction du taux de rachat\n structurel",
         xlab = "Taux de rachat",
         ylab = "BE"
   )
     abline(h=1)}


```

Conformément à nos attentes, les BE convergent bien vers le prix de l'actif en $0$ comme démontré plus haut. Seul le taux de rachat semble ici avoir une influence sur la vitesse de convergence du BE. En effet, on observe une diminution de la dispersion des BE estimés avec la hausse du taux de rachat, indiquant ainsi une augmentation de la vitesse de convergence. Une explication de cet effet serait de considérer qu'une augmentation du taux de rachat induirait que l'unique flux financier généré par le contrat intervienne plus souvent avant le terme du contrat, réduisant ainsi l'influence de la volatilité du sous-jacent.

\newpage
# IV. Conclusion

Conformément à la démonstration proposée en partie III, le BE reste stable malgré la perturbation de chaque paramètre de notre modèle. Une étude intéressante à mener serait la sensibilité de la vitesse de convergence aux variations des différents paramètres.
Mathématiquement, le BE est dans Sovalibité II une espérance (ordre 1). Ainsi nous le calculons avec une approche "juste", que l'on pourrais opposer à une approche "prudente" en comptes sociaux. La faible complexité du cadre posé permet de tirer des résultats théoriques intéressants et de les confirmer par la simulation, même s'il est évident que dans la pratique d'autres paramètres seraient à prendre en compte.

*Référence* :

* http://www.ressources-actuarielles.net/EXT/ISFA/fp-isfa.nsf/34a14c286dfb0903c1256ffd00502d73/a5e99e9abf5d3674c125772f00600f6c/$FILE/ESG.pdf - Site de M. PLANCHET, documentation de la librairie ESG
